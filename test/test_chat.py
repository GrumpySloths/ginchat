from transformers import AutoTokenizer, AutoModel
tokenizer = AutoTokenizer.from_pretrained("THUDM/chatglm2-6b", trust_remote_code=True)
model = AutoModel.from_pretrained("THUDM/chatglm2-6b", trust_remote_code=True, device='cuda')
model = model.eval()
response, history = model.chat(tokenizer, "ä½ å¥½", history=[])
print(response)
# ä½ å¥½ðŸ‘‹!æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM2-6B,å¾ˆé«˜å…´è§åˆ°ä½ ,æ¬¢è¿Žé—®æˆ‘ä»»ä½•é—®é¢˜ã€‚
# >>> response, history = model.chat(tokenizer, "æ™šä¸Šç¡ä¸ç€åº”è¯¥æ€Žä¹ˆåŠž", history=history)
# >>> print(response)
